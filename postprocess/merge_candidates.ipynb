{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b2d1ff",
   "metadata": {},
   "source": [
    "# Exploring the AIND-ephys outputs using SpikeInterface\n",
    "\n",
    "### Notebook usage:\n",
    "- This notebook assumes some comfort with spike sorting and electrophysiology data. In addition, a basic understanding of [SpikeInterface](https://spikeinterface.readthedocs.io/en/latest/index.html) is helpful.\n",
    "\n",
    "- This notebook will compare units based on QC metrics and template similarity and provide a list of units to further explore. The units are the most similar in euclidean space after UMAP dimensionality reduction then are thresholded based on probe location and template similarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f928da24",
   "metadata": {},
   "source": [
    "#### Requirements:\n",
    "- processed AINDS neuropixels data\n",
    "- installation of spikeinterface - if not installed, please install SpikeInterace using the following command:\n",
    "```bash\n",
    "pip install \"spikeinterface[full, widgets]\"\n",
    "```\n",
    "\n",
    "**Note**: This notebook is based on the latest version of SpikeInterface (`spikeinterface==0.101.0`) which is under development. The API may change in the future and *is* different from the version used in the AINDS pipeline (`spikeinterface==0.100.8`). We have adapted the notebook to work with the latest version of SpikeInterface since there is a significant improvement in the API and functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff4d2fe2-bc6c-4d7f-81dd-eacb102f32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.widgets as sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5e9de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch data directories\n",
    "\n",
    "raw_rec = 'path/to/raw/recording'\n",
    "baseFolder = r\"C:\\Users\\janet\\Documents\\Ally_AINDS_output\\2022_10_27_AEG26_g0_imec0\" #edit this to the location of your data\"\n",
    "experiment = 'block0_imec0.ap_recording1' #edit this to the name of your experiment folder\n",
    "\n",
    "preProcessed = baseFolder + '/preprocessed'\n",
    "postProcessed = baseFolder + '/postprocessed'\n",
    "spikes = baseFolder + '/spikesorted'\n",
    "curated = baseFolder + '/curated'\n",
    "preJSON = os.path.join(preProcessed, experiment + '.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b962ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the data to explore\n",
    "\n",
    "data_load = curated\n",
    "print(f'Set path: {data_load}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b340228",
   "metadata": {},
   "source": [
    "## First, let's load the waveform extractor - we'll explore the postprocessed units which are stored in the `postprocessed` folder. These units have been processed to include the following: \n",
    "* removal of duplicate units\n",
    "* computed amplitudes\n",
    "* spike/unit locations \n",
    "* PCA\n",
    "* correlograms\n",
    "* template similarity\n",
    "* templeate metrics\n",
    "* QC metrics\n",
    "\n",
    "## The `curated` folder includes units that *have been* automatically curated by:\n",
    "* ISI violation ratio\n",
    "* presence ratio\n",
    "* amplitude cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862500d9",
   "metadata": {},
   "source": [
    "### First, load the wave forms and the sorting extractor\n",
    "*Note: we will use the back compatible version of the waveform extractor which is the `MockWaveformExtractor` that is used in the latest version of SpikeInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e400ae9-0058-40ae-bb29-f1306c2ccbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "we =  si.load_waveforms(folder=(os.path.join(postProcessed, experiment)))\n",
    "sorting_curated = si.load_extractor(os.path.join(data_load, experiment))\n",
    "we, sorting_curated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9738ae7e",
   "metadata": {},
   "source": [
    "### The available extensions within the waveform extractor will be printed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_extensions = we.get_available_extension_names()\n",
    "print(f\"Extensions available in MockWaveformExtractor {avail_extensions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e436735",
   "metadata": {},
   "source": [
    "### Create sorting analyzer and fetch quality metrics and unit information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26a50d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_analyzer = we.sorting_analyzer\n",
    "\n",
    "#quality metrics\n",
    "qm=sorting_analyzer.get_extension(extension_name='quality_metrics').get_data()\n",
    "#fetch decoder labels (e.g. SUA, MUA, noise)\n",
    "labels = sorting_curated.get_property('decoder_label')\n",
    "#fetch unit ids and locations\n",
    "unit_ids = sorting_curated.get_unit_ids()\n",
    "unit_locations = sorting_analyzer.get_extension(\"unit_locations\").get_data()\n",
    "unit_locations = unit_locations[:,1]\n",
    "#isi_histograms = sorting_analyzer.get_extension(\"isi_histograms\").get_data()\n",
    "#fetch template similarity for each unit\n",
    "template_similarity = sorting_analyzer.get_extension(extension_name='template_similarity').get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7058532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to dataframe for easier manipulation\n",
    "template_sim = pd.DataFrame(template_similarity, columns=unit_ids, index=unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a009231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe of all the quality metrics\n",
    "df = pd.DataFrame(qm)\n",
    "df['unit_ids'] = unit_ids\n",
    "df['labels'] = labels\n",
    "df['unit_locations'] = unit_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6bdbfd",
   "metadata": {},
   "source": [
    "### Drop features that are not needed for the analysis, these can be edited based on your preference/needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ff5c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['sync_spike_2', 'sync_spike_4', 'sync_spike_8', 'amplitude_cv_range', 'drift_mad']\n",
    "df = df.drop(features_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f61417",
   "metadata": {},
   "source": [
    "### Sum of units within the selected recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ea8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum up sua, mua, noise\n",
    "print('Sum of all labels/units:', len(df))\n",
    "print('Total SUAs:', len(df[df['labels']=='sua']))\n",
    "print('Total MUAs:', len(df[df['labels']=='mua']))\n",
    "print('Total noise:', len(df[df['labels']=='noise']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1074b615",
   "metadata": {},
   "source": [
    "## Now, we'll begin to explore the units based on QC metrics and reduce the dimensionality of the units using UMAP. We'll use this to compare the units based on similarity and location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#umap of all quality metrics\n",
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "scaled_df = df.drop(columns=['unit_ids', 'labels'])\n",
    "#take median of each column in scaled_df\n",
    "fill_value = scaled_df.median()\n",
    "scaled_df = scaled_df.fillna(fill_value)\n",
    "embedding = reducer.fit_transform(scaled_df)\n",
    "print(f\"UMAP shape: {embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4cbddb",
   "metadata": {},
   "source": [
    "### We will now create an interactive UMAP plot using bokeh to explore the units based on similarity and location. You can zoom in/out on each cluster to explore the units in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb89e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make interactive plot with bokeh\n",
    "import bokeh\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper\n",
    "from bokeh.palettes import Spectral10\n",
    "\n",
    "df_filtered = df[(df['labels'] != 'noise') & (df['presence_ratio']>0.8)] \n",
    "df_filtered_copy = df_filtered.copy() \n",
    "unique_labels = df_filtered['labels'].unique()\n",
    "color_mapper = CategoricalColorMapper(factors=unique_labels, palette=Spectral10)\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "# Create a ColumnDataSource from df. These will be displayed in the plot when we hover over the data points.\n",
    "source = ColumnDataSource(data=dict(\n",
    "    x=embedding[:, 0],\n",
    "    y=embedding[:, 1],\n",
    "    unit_ids=df_filtered['unit_ids'],\n",
    "    unit_locations=df_filtered['unit_locations'],\n",
    "    amplitude_median=df_filtered['amplitude_median'],\n",
    "    firing_range=df_filtered['firing_range'],\n",
    "    snr=df_filtered['snr'],\n",
    "    d_prime=df_filtered['d_prime'],\n",
    "    labels=df_filtered['labels']\n",
    "))\n",
    "\n",
    "# Create a HoverTool\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"unit_ids\", \"@unit_ids\"),\n",
    "    (\"unit_locations\", \"@unit_locations\"),\n",
    "    (\"amplitude_median\", \"@amplitude_median\"),\n",
    "    (\"firing_range\", \"@firing_range\"),\n",
    "    (\"snr\", \"@snr\"),\n",
    "    (\"d_prime\", \"@d_prime\"),\n",
    "    (\"labels\", \"@labels\")\n",
    "])\n",
    "\n",
    "# Create a figure\n",
    "p = figure(width=600, height=600, tools=[hover, 'pan', 'reset', 'box_zoom'], title='UMAP of select quality metrics')\n",
    "\n",
    "# Add circle glyphs to the figure p\n",
    "p.scatter('x', 'y', source=source, color=dict(field='labels', transform=color_mapper), legend_field='labels', size=12)\n",
    "\n",
    "# Set the legend.location attribute of the plot to 'top_right'\n",
    "p.legend.location = 'top_right'\n",
    "\n",
    "# Show the plot\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb5d0b6",
   "metadata": {},
   "source": [
    "### After exploring the units, we will threshold the units based on probe location and template similarity. We will then provide a list of units to further explore for potential merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f26e7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find pairs of units that are close together\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_df = scaler.fit_transform(df_filtered_copy.drop(columns=['unit_ids', 'labels']).fillna(0))\n",
    "\n",
    "#calculate euclidean distances\n",
    "distances = euclidean_distances(scaled_df, scaled_df)\n",
    "distances_df = pd.DataFrame(distances, columns=df_filtered_copy['unit_ids'], index=df_filtered_copy['unit_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b551ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find pairs of units that are close together\n",
    "close_units = []\n",
    "for i in range(len(distances_df)):\n",
    "    for j in range(i+1, len(distances_df)):\n",
    "        if distances_df.iloc[i, j] < 2:\n",
    "            close_units.append((distances_df.index[i], distances_df.columns[j]))\n",
    "\n",
    "#close units to dataframe, map labels\n",
    "df_close_units = pd.DataFrame(close_units, columns=['unit1', 'unit2'])\n",
    "df_close_units['label1'] = df_close_units['unit1'].map(df_filtered.set_index('unit_ids')['labels'])\n",
    "df_close_units['label2'] = df_close_units['unit2'].map(df_filtered.set_index('unit_ids')['labels'])\n",
    "#remove units that are more than 5 units apart\n",
    "df_close_units = df_close_units[df_close_units['unit2'] - df_close_units['unit1'] < 5]\n",
    "df_close_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49b012a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = pd.DataFrame()\n",
    "sim_df['unit_ids']=df_close_units[['unit1', 'unit2']].values.flatten()\n",
    "#remove duplicates\n",
    "sim_df = sim_df.drop_duplicates()\n",
    "\n",
    "if not set(sim_df['unit_ids']).issubset(set(distances_df.columns) & set(template_sim.columns)):\n",
    "    raise ValueError(\"Unit IDs in sim_df must be present in both distances_df and template_sim.\")\n",
    "\n",
    "# Create a new DataFrame with the unit IDs from sim_df\n",
    "result_df = pd.DataFrame(index=sim_df['unit_ids'])\n",
    "\n",
    "# Iterate over the unit IDs in sim_df\n",
    "for unit_id in sim_df['unit_ids']:\n",
    "    # Extract the corresponding rows from distances_df and template_sim\n",
    "    distance_row = distances_df[unit_id]\n",
    "    similarity_row = template_sim[unit_id]\n",
    "\n",
    "    # Calculate the ratio of similarity to distance for each element\n",
    "    ratio = similarity_row / distance_row\n",
    "\n",
    "    # Add the ratio to the result DataFrame\n",
    "    result_df[unit_id] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e6580d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_id_to_label = {}\n",
    "for index, row in df_close_units.iterrows():\n",
    "    unit_id1 = row['unit1']\n",
    "    unit_id2 = row['unit2']\n",
    "    label1 = row['label1']\n",
    "    label2 = row['label2']\n",
    "    unit_id_to_label[unit_id1] = {'unit1': label1, 'unit2': label2}\n",
    "    unit_id_to_label[unit_id2] = {'unit1': label1, 'unit2': label2}\n",
    "\n",
    "\n",
    "# Filter result_df to include only the rows and columns with unit IDs that have labels\n",
    "filtered_df = result_df.loc[unit_id_to_label.keys(), unit_id_to_label.keys()]\n",
    "\n",
    "#create a filtered distances dataframe\n",
    "filtered_distances_df = distances_df.loc[unit_id_to_label.keys(), unit_id_to_label.keys()]\n",
    "# Get template similarity values for the unit IDs in df_close_units\n",
    "filtered_template_sim = template_sim.loc[unit_id_to_label.keys(), unit_id_to_label.keys()]\n",
    "\n",
    "# Create a new dataframe to store the extracted distances\n",
    "extracted_distances_df = pd.DataFrame(index=filtered_distances_df.index, columns=filtered_distances_df.columns)\n",
    "extracted_template_sim_df = pd.DataFrame(index=filtered_template_sim.index, columns=filtered_template_sim.columns)\n",
    "\n",
    "# Iterate through the filtered dataframe to extract distances based on labels\n",
    "for i, row in filtered_distances_df.iterrows():\n",
    "    for j, col in filtered_distances_df.iterrows():\n",
    "        # Check if the pair of unit IDs is in df_close_units\n",
    "        if i != j and any((i, j) == (row.unit1, row.unit2) for row in df_close_units.itertuples()):\n",
    "            label1 = unit_id_to_label[i]\n",
    "            label2 = unit_id_to_label[j]\n",
    "            extracted_distances_df.loc[i, j] = filtered_distances_df.loc[i, j]\n",
    "extracted_distances_df = extracted_distances_df.where(np.triu(extracted_distances_df.to_numpy() != np.nan, k=1))\n",
    "\n",
    "for i, row in filtered_template_sim.iterrows():\n",
    "    for j, col in filtered_template_sim.iterrows():\n",
    "        # Check if the pair of unit IDs is in df_close_units\n",
    "        if i != j and any((i, j) == (row.unit1, row.unit2) for row in df_close_units.itertuples()):\n",
    "            label1 = unit_id_to_label[i]\n",
    "            label2 = unit_id_to_label[j]\n",
    "            extracted_template_sim_df.loc[i, j] = filtered_template_sim.loc[i, j]\n",
    "extracted_template_sim_df = extracted_template_sim_df.where(np.triu(extracted_template_sim_df.to_numpy() !=np.nan, k=1))\n",
    "\n",
    "# Stack the dataframe to get a single value for each pair\n",
    "stacked_distances_df = extracted_distances_df.stack()\n",
    "stacked_distances_df.columns = ['unit1', 'unit2', 'distance']\n",
    "stacked_distances_df=pd.DataFrame(stacked_distances_df)\n",
    "\n",
    "stacked_template_sim_df = extracted_template_sim_df.stack()\n",
    "stacked_template_sim_df.columns = ['unit1', 'unit2', 'similarity']\n",
    "stacked_template_sim_df=pd.DataFrame(stacked_template_sim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63ee7bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming for clarity\n",
    "stacked_template_sim_df.rename(columns={0: 'similarity'}, inplace=True)\n",
    "stacked_template_sim_df['unit1'] = stacked_template_sim_df.index.get_level_values(0)\n",
    "stacked_template_sim_df['unit2'] = stacked_template_sim_df.index.get_level_values(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c5f35d",
   "metadata": {},
   "source": [
    "## Candidates for merging based on distance. We will then filter based on template similarity and assess their cross-correlograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bbbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_template_sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7904420",
   "metadata": {},
   "source": [
    "## Let's look at the crosscorrelograms for the candidates. A template similarity threshold is set here to be > 0.6 but this can be adjusted based on preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bfc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot crosscorrelograms for pairs of units\n",
    "from spikeinterface.widgets import plot_crosscorrelograms\n",
    "\n",
    "# Filter unit pairs based on similarity threshold\n",
    "sim_threshold = 0.6\n",
    "filtered_units = stacked_template_sim_df[stacked_template_sim_df['similarity'] > sim_threshold]\n",
    "unit_ids = filtered_units[['unit1', 'unit2']].values\n",
    "print(f\"Number of unit pairs with similarity > {sim_threshold}: {len(unit_ids)}\")\n",
    "\n",
    "for i, (unit1, unit2) in enumerate(unit_ids):\n",
    "    plot_crosscorrelograms(sorting_curated, unit_ids=[unit1, unit2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d98072",
   "metadata": {},
   "source": [
    "### Because the counts can vary widely between units, we can plot the correlograms on top of each other to compare the shape of the correlograms along with spike counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8168a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_unit_ids = unit_ids.flatten()  \n",
    "\n",
    "from spikeinterface.postprocessing import compute_correlograms\n",
    "spike_extractor = si.load_extractor(os.path.join(spikes, experiment)) #to look like plot_correlograms def, cannot use stored correlograms\n",
    "correlograms,bins = compute_correlograms(spike_extractor, window_ms=50.0, bin_ms=1.0) #same params as workflow\n",
    "\n",
    "rp_t = 1.0 #in ms (refractory period threshold)\n",
    "bar_centers = bins[:-1] + (bins[1] - bins[0]) / 2\n",
    "\n",
    "for i, (unit1, unit2) in enumerate(unit_ids):\n",
    "    isi_violations = df[(df['unit_ids'] == unit1) | (df['unit_ids'] == unit2)]['isi_violations_count']\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(bar_centers, correlograms[unit1, unit1,:], width=bins[1] - bins[0], color=\"CornflowerBlue\", alpha=0.7, label=f\"unit {unit1}\")\n",
    "    plt.bar(bar_centers, correlograms[unit2, unit2,:], width=bins[1] - bins[0], color=\"Thistle\", alpha=0.7, label=f\"unit {unit2}\")\n",
    "\n",
    "    # Add vertical lines\n",
    "    plt.axvline(x=-rp_t, color=\"Crimson\", linestyle=\"dashed\", linewidth=1, label=\"RP Threshold (-)\")\n",
    "    plt.axvline(x=rp_t, color=\"Crimson\", linestyle=\"dashed\", linewidth=1, label=\"RP Threshold (+)\")\n",
    "\n",
    "    # Customize plot\n",
    "    plt.text(0.05, 0.95, f'ISI violations: {isi_violations.values}', fontsize=12, transform=plt.gca().transAxes, verticalalignment='top')\n",
    "    plt.xlabel(\"Bins\")\n",
    "    plt.ylabel(\"Counts (spike matches/bin)\")\n",
    "    plt.title(\"auto-correlogram\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de93fcb",
   "metadata": {},
   "source": [
    "## We can now compare the potential units for merging based on QC similarity to the `get_potential_auto_merge` function in spikeinterface. This function will return a list of units that are potential candidates for merging based on the user's input. These are likely to not agree since we have thresholded the units based on probe location and template similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583820be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test get_potential_merge from spikeinterface \n",
    "from spikeinterface.curation import get_potential_auto_merge\n",
    "merge_unit_pairs = get_potential_auto_merge(\n",
    "    sorting_analyzer,\n",
    "    preset=\"similarity_correlograms\", #others include: x_contaiminations, temporal_splits, feature_neighbors\n",
    "    resolve_graph=True,\n",
    "    corr_diff_thresh=0.5,\n",
    ")\n",
    "print(f'Potential total unit pairs to merge from SI: {len(merge_unit_pairs)}')\n",
    "print(f'Potential unit ids to merge from SI: {merge_unit_pairs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d43a05e",
   "metadata": {},
   "source": [
    "## Easy merging of units can be done using the webapp. All of the available figurl links are within the `visualization_output.json` file and contains a timeseries summary and a sorting summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull webadress from json\n",
    "import json\n",
    "\n",
    "json_path = baseFolder + '/visualization_output.json'\n",
    "with open(json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    current_data_url = data[experiment]['sorting_summary']\n",
    "\n",
    "print(f'Open the sorting summary dashboard at: {current_data_url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e65ff2",
   "metadata": {},
   "source": [
    "## `plot_unit_summary` provides a unit-by-unit summary throughout the recording. The following will plot:\n",
    "- the unit's location\n",
    "- the unit's waveform across channels\n",
    "- the unit's waveform\n",
    "- the unit's autocorrelogram\n",
    "- the unit's amplitude across the recording\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d2243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot unit summary for pairs of units\n",
    "from spikeinterface.widgets import plot_unit_summary\n",
    "\n",
    "for i, (unit1, unit2) in enumerate(unit_ids):\n",
    "    plot_unit_summary(sorting_analyzer, unit_id=unit1)\n",
    "    plot_unit_summary(sorting_analyzer, unit_id=unit2)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8580b35c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikeinterface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
