{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "* [0. Preparation](#preparation)\n",
    "* [1. Reading recording and sorting](#loading)\n",
    "* [2. Preprocessing](#preprocessing)\n",
    "* [3. Saving and loading SpikeInterface objects](#save-load)\n",
    "* [4. Data compression](#compression)\n",
    "* [5. Extracting waveforms](#waveforms)\n",
    "* [6. Postprocessing](#postprocessing)\n",
    "* [7. Validation and curation](#curation)\n",
    "* [8. Viewers](#viewers)\n",
    "* [9. Spike sorting comparison](#comparison)\n",
    "* [10. Exporters](#exporters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparation <a class=\"anchor\" id=\"preparation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se \n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.widgets as sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpikeInterface version: 0.96.2.dev0\n"
     ]
    }
   ],
   "source": [
    "print(f\"SpikeInterface version: {si.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading recording <a class=\"anchor\" id=\"loading\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = Path(r\"D:\\Vincent\\Data\\sc011\\sc011_0106\\sc011_0106_001\")\n",
    "file_path = r\"D:\\Vincent\\Data\\sc011\\sc011_0106\\sc011_0106_001\\Record Node 101\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `extractor` module allows you to load many file formats used in electrophysiology. \n",
    "\n",
    "The extractors available in SI are all loaded using the [NEO](https://neo.readthedocs.io/en/stable/) python package.\n",
    "\n",
    "We can access the full list of available extractors with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary': spikeinterface.core.binaryrecordingextractor.BinaryRecordingExtractor,\n",
       " 'numpy': spikeinterface.core.numpyextractors.NumpyRecording,\n",
       " 'shybrid': spikeinterface.extractors.shybridextractors.SHYBRIDRecordingExtractor,\n",
       " 'mda': spikeinterface.extractors.mdaextractors.MdaRecordingExtractor,\n",
       " 'nwb': spikeinterface.extractors.nwbextractors.NwbRecordingExtractor,\n",
       " 'cbin_ibl': spikeinterface.extractors.cbin_ibl.CompressedBinaryIblExtractor,\n",
       " 'mcsh5': spikeinterface.extractors.mcsh5extractors.MCSH5RecordingExtractor,\n",
       " 'alphaomega': spikeinterface.extractors.neoextractors.alphaomega.AlphaOmegaRecordingExtractor,\n",
       " 'axona': spikeinterface.extractors.neoextractors.axona.AxonaRecordingExtractor,\n",
       " 'biocam': spikeinterface.extractors.neoextractors.biocam.BiocamRecordingExtractor,\n",
       " 'blackrock': spikeinterface.extractors.neoextractors.blackrock.BlackrockRecordingExtractor,\n",
       " 'ced': spikeinterface.extractors.neoextractors.ced.CedRecordingExtractor,\n",
       " 'edf': spikeinterface.extractors.neoextractors.edf.EDFRecordingExtractor,\n",
       " 'intan': spikeinterface.extractors.neoextractors.intan.IntanRecordingExtractor,\n",
       " 'maxwell': spikeinterface.extractors.neoextractors.maxwell.MaxwellRecordingExtractor,\n",
       " 'mearec': spikeinterface.extractors.neoextractors.mearec.MEArecRecordingExtractor,\n",
       " 'mcsraw': spikeinterface.extractors.neoextractors.mcsraw.MCSRawRecordingExtractor,\n",
       " 'neuralynx': spikeinterface.extractors.neoextractors.neuralynx.NeuralynxRecordingExtractor,\n",
       " 'neuroscope': spikeinterface.extractors.neoextractors.neuroscope.NeuroScopeRecordingExtractor,\n",
       " 'nix': spikeinterface.extractors.neoextractors.nix.NixRecordingExtractor,\n",
       " 'openephys': spikeinterface.extractors.neoextractors.openephys.OpenEphysBinaryRecordingExtractor,\n",
       " 'openephyslegacy': spikeinterface.extractors.neoextractors.openephys.OpenEphysLegacyRecordingExtractor,\n",
       " 'plexon': spikeinterface.extractors.neoextractors.plexon.PlexonRecordingExtractor,\n",
       " 'spike2': spikeinterface.extractors.neoextractors.spike2.Spike2RecordingExtractor,\n",
       " 'spikegadgets': spikeinterface.extractors.neoextractors.spikegadgets.SpikeGadgetsRecordingExtractor,\n",
       " 'spikeglx': spikeinterface.extractors.neoextractors.spikeglx.SpikeGLXRecordingExtractor,\n",
       " 'tdt': spikeinterface.extractors.neoextractors.tdt.TdtRecordingExtractor}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se.recording_extractor_full_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = se.read_openephys(file_path, stream_id='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenEphysBinaryRecordingExtractor: 384 channels - 1 segments - 30.0kHz - 712.440s"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `RecordingExtractor` object extracts information about channel ids, channel locations (if present), the sampling frequency of the recording, and the extracellular traces (when prompted).\n",
    "Here we retrieve information from the recording using the built-in functions from the RecordingExtractor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = recording.get_channel_ids()\n",
    "fs = recording.get_sampling_frequency()\n",
    "num_chan = recording.get_num_channels()\n",
    "num_segments = recording.get_num_segments()\n",
    "\n",
    "print(f'Channel ids: {channel_ids}')\n",
    "print(f'Sampling frequency: {fs}')\n",
    "print(f'Number of channels: {num_chan}')\n",
    "print(f\"Number of segments: {num_segments}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpikeInterface supports multi-segment recordings. A segment is a contiguous piece of data, and sometimes recordings can be made of multiple acquisitions, for examples a baseline, a stimulation phase, and a post recording. In such cases, the recording object will be made of multiple segments and be treated as such over the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `get_traces()` function returns a TxN numpy array where N is the number of channel ids passed in (all channel ids are passed in by default) and T is the number of frames (determined by start_frame and end_frame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trace_snippet = recording.get_traces(start_frame=int(fs*0), end_frame=int(fs*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Traces shape:', trace_snippet.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Before moving on with the analysis, let's check the probe information. \n",
    "`SpikeInterface` internally uses an additional package, named [ProbeInterface](https://probeinterface.readthedocs.io/en/main/index.html), to handle probe devices. \n",
    "\n",
    "For NWB files, the probe information is loaded automatically from the file, so we can directly access its information and channel locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = recording.get_probe()\n",
    "print(probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(probe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_probe_map(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `widgets` module includes several convenient plotting functions that can be used to explore the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ts = sw.plot_timeseries(recording, order_channel_by_depth=True, backend=\"ipywidgets\",\n",
    "                          clim=(-200, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Properties \n",
    "\n",
    "`RecordingExtractor` object can have *properties*. A property is a piece of information attached to a channel, e.g. group or location.\n",
    "\n",
    "Similarly, for `SortingExtractor` objects (that we'll cover later), anything related to a unit can be stored as a property. \n",
    "\n",
    "We can check which properties are in the extractor as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Properties:\\n\", list(recording.get_property_keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's add some new properties! \n",
    "The first 192 channels are in the CA1 area, the second 192 are in the CA3 area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# brain_area_property_values = ['CA1']*192 + ['CA3']*192\n",
    "# print(brain_area_property_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording.set_property(key='brain_area', values=brain_area_property_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also specify a property on a subset of channels. In this case, the non-specified channels will be filled empty values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# recording.set_property(key='quality', values=[\"good\"]*(recording_nwb.get_num_channels() - 3),\n",
    "#                            ids=recording_nwb.get_channel_ids()[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording.get_property(\"quality\")[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Properties after adding custom properties:\\n\", list(recording_nwb.get_property_keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Internally the properties is just a dictionary attached to the recording that is accessible as `_properties`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recording._properties.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Annotations* can be attached to any object and they can carry any information related to the recording or sorting objects.\n",
    "\n",
    "Let's add an annotation about this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recording.annotate(description=\"First in-vivo NPX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recording.get_annotation_keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing <a class=\"anchor\" id=\"preprocessing\"></a>\n",
    "\n",
    "\n",
    "Now that the probe information is loaded we can do some preprocessing using `preprocessing` module.\n",
    "\n",
    "We can filter the recordings, rereference the signals to remove noise, discard noisy channels, whiten the data, remove stimulation artifacts, etc. (more info [here](https://spiketoolkit.readthedocs.io/en/latest/preprocessing_example.html)).\n",
    "\n",
    "For this notebook, let's filter the recordings and apply common median reference (CMR). All preprocessing modules return new `RecordingExtractor` objects that apply the underlying preprocessing function. This allows users to access the preprocessed data in the same way as the raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = spre.phase_shift(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_f = spre.highpass_filter(recording, freq_min=300)\n",
    "# recording = spre.bandpass_filter(recording, freq_min=300, freq_max=6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can `annotate` the recording to tell SI that it is filtered. This information is useful later in the pipeline, when extracting waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.annotate(is_filtered=False)\n",
    "recording_f.annotate(is_filtered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Median Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cmr = spre.common_reference(recording_f, reference='global', operator='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the traces after applying CMR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_timeseries({\"raw\": recording, \"filt\": recording_f, \"common\": recording_cmr},\n",
    "                        clim=(-50, 50), time_range=[10, 10.1], order_channel_by_depth=True,\n",
    "                        backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Saving and loading SpikeInterface objects <a class=\"anchor\" id=\"save-load\"></a>\n",
    "\n",
    "All operations in SpikeInterface are *lazy*, meaning that they are not performed if not needed. This is why the creation of our filter recording was almost instantaneous. However, to speed up further processing, we might want to **save** it to a file and perform those operations (eg. filters, CMR, etc.) at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_kwargs = dict(n_jobs=10, chunk_duration=\"1s\", progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if (base_folder / \"preprocessed\").is_dir():\n",
    "    recording_saved = si.load_extractor(base_folder / \"preprocessed\")\n",
    "else:\n",
    "    recording_saved = recording_cmr.save(folder=base_folder / \"preprocessed\", **job_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If we inspect the `preprocessed` folder, we find that a few files have been saved. Let's take a look at what they are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ls {base_folder}/preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `traces_cached_seg0.raw` contains the processed raw data, while the `.json` files include information on how to reload the binary file. The `provenance.json` includes the information of the recording before saving it to a binary file, and the `probe.json` represents the probe object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `save` returns a new *cached* recording that has all the previously loaded information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Cached channels ids: {recording_saved.get_channel_ids()}')\n",
    "print(f'Channel groups after caching: {recording_saved.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After saving the SI object, we can easily load it back in a new session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recording_loaded = si.load_extractor(base_folder / \"preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Loaded channels ids: {recording_loaded.get_channel_ids()}')\n",
    "print(f'Channel groups after loading: {recording_loaded.get_channel_groups()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double check that the traces are exactly the same as the `recording_saved` that we saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_timeseries({\"preprocessed\": recording_cmr, \"saved\": recording_saved, \"loaded\": recording_loaded},\n",
    "                        clim=(-50, 50), mode=\"line\",\n",
    "                        backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**IMPORTANT**: the same saving mechanisms are available also for all SortingExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Spike sorting <a class=\"anchor\" id=\"spike-sorting\"></a>\n",
    "\n",
    "We can now run spike sorting on the above recording. We will use different spike sorters for this demonstration, to show how easy SpikeInterface makes it easy to interchengably run different sorters :)\n",
    "\n",
    "Let's first check the available and installed sorters in `SpikeInterface`.\n",
    "We will sort the bandpass cached filtered recording the `recording_saved` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.available_sorters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.installed_sorters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `spikeinterface.sortingcomponents` module includes functions that can be used to create custom spike sorting pipelines built-in in `SpikeInterface`. It is still experimental and under heavy development, but there are already two SI-based sorters available:\n",
    "\n",
    "* `tridesclous2` (developed by Samuel Garcia)\n",
    "* `spykingcircus2` (developed by Pierre Yger)\n",
    "\n",
    "They can be run with the same `run_sorter` function, but they don't require any additional installation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the parameters associated to any sorter with the `get_default_params()` function from the `sorters` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ss.get_default_sorter_params('kilosort2_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ss.run_sorter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To modify a parameter, we can easily pass it to the `run` function as an extra argument!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run sorter locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorter_params = job_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run spike sorting on entire recording\n",
    "# sorting_KS25 = ss.run_sorter('kilosort2_5', recording_saved,\n",
    "#                              output_folder=base_folder / 'results_KS25',\n",
    "#                              verbose=True, **sorter_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('KS25 found', len(sorting_KS25.get_unit_ids()), 'units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting_KS25 = sorting_KS25.remove_empty_units()\n",
    "# print(f'KS25 found {len(sorting_KS25.get_unit_ids())} non-empty units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SpikeInterface ensures full provenance of the spike sorting pipeline. Upon running a spike sorter, a `spikeinterface_params.json` file is saved in the `output_folder`. This contains a `.json` version of the recording and all the input parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !ls {base_folder}/results_KS25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat {base_folder}/results_KS25/spikeinterface_params.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The spike sorting returns a `SortingExtractor` object. Let's see some of its functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Spike train of a unit: {sorting_KS25.get_unit_spike_train(1)}')\n",
    "# print(f'Spike train of a unit (in s): {sorting_KS25.get_unit_spike_train(1, return_times=True)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can use `spikewidgets` functions for some quick visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# w_rs = sw.plot_rasters(sorting_KS25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save a spike sorting output for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting_saved_KS25 = sorting_KS25.save(folder=\"sorting_KS25\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run sorter in container\n",
    "\n",
    "Some sorters are hard to install! To alleviate this headache, SI provides a built-in mechanism to run a spike sorting job in a docker container.\n",
    "\n",
    "We are maintaining a set of sorter-specific docker files in the [spikeinterface-dockerfiles repo](<https://github.com/SpikeInterface/spikeinterface-dockerfiles>)\n",
    "and most of the docker images are available on Docker Hub from the [SpikeInterface organization](<https://hub.docker.com/orgs/spikeinterface/repositories>).\n",
    "\n",
    "Running spike sorting in a docker container just requires to:\n",
    "\n",
    "1. have docker/singularity installed\n",
    "2. have docker/singularity python SDK installed (`pip install docker/spython`)\n",
    "\n",
    "When docker/singularity is installed, you can simply run the sorter in a container image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorter_params = job_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run spike sorting on entire recording\n",
    "sorting_KS25 = ss.run_kilosort2_5(recording_saved, \n",
    "                            output_folder=base_folder / 'results_KS2_5',\n",
    "                            verbose=True, docker_image=True, \n",
    "                            **sorter_params)\n",
    "# Note: can't run with singularity_image on Windows because of import pwd error. Use docker_image instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorting_KS25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'KS2.5 found {len(sorting_KS25.get_unit_ids())} units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_KS25 = sorting_KS25.remove_empty_units()\n",
    "print(f'KS2.5 found {len(sorting_KS25.get_unit_ids())} non-empty units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Extracting waveforms <a class=\"anchor\" id=\"waveforms\"></a>\n",
    "\n",
    "The core of postprocessing spike sorting results revolves around extracting waveforms from paired recording-sorting objects.\n",
    "\n",
    "In the SI API, waveforms are extracted using the `WaveformExtractor` class in the `core` module.\n",
    "\n",
    "The `WaveformExtractor` object has convenient functions to retrieve waveforms and templates.\n",
    "Let's see how it works.\n",
    "\n",
    "To extract the waveforms, we can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_saved = si.load_extractor(base_folder / \"preprocessed\")\n",
    "sorting = sorting_KS25\n",
    "print(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "si.extract_waveforms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we = si.extract_waveforms(recording_saved, sorting, folder=base_folder / \"waveforms\", \n",
    "                          load_if_exists=False, overwrite=True, **job_kwargs)\n",
    "print(we)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now all waveforms are computed and stored in the provided `waveforms` folder. We can now retrieve waveforms and templates easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms0 = we.get_waveforms(unit_id=0)\n",
    "print(f\"Waveforms shape: {waveforms0.shape}\")\n",
    "template0 = we.get_template(unit_id=0)\n",
    "print(f\"Template shape: {template0.shape}\")\n",
    "all_templates = we.get_all_templates()\n",
    "print(f\"All templates shape: {all_templates.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For waveforms, the dimension is (num_spikes, num_samples, num_channels), while each template has dimension (num_samples, num_channels). Note that the number of spikes in this case is 500..we'll get back to it later!\n",
    "\n",
    "The `WaveformExtractor` is also compatible with several `widgets` to visualize the spike sorting output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEW in v0.95**: we can also render interactive plots with the `ipywidgets` backend!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_unit_templates(we, radius_um=30, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we noticed before, the number of spikes for the waveforms is 500. Let's check the number of spikes for other waveforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unit in sorting.get_unit_ids():\n",
    "    waveforms = we.get_waveforms(unit_id=unit)\n",
    "    spiketrain = sorting.get_unit_spike_train(unit)\n",
    "    print(f\"Unit {unit} - num waveforms: {waveforms.shape[0]} - num spikes: {len(spiketrain)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No units have more than 500 spikes! This is because by default, the `WaveformExtractor` extracts waveforms on a random subset of 500 spikes. To extract waveforms on all spikes, we can use the `max_spikes_per_unit` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_all = si.extract_waveforms(recording_saved, sorting, folder=base_folder / \"waveforms_all\", \n",
    "                              max_spikes_per_unit=None,\n",
    "                              overwrite=True,\n",
    "                              **job_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unit in sorting.get_unit_ids():\n",
    "    waveforms = we_all.get_waveforms(unit_id=unit)\n",
    "    spiketrain = sorting.get_unit_spike_train(unit)\n",
    "    print(f\"Unit {unit} - num waveforms: {waveforms.shape[0]} - num spikes: {len(spiketrain)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now waveforms have been extracted for all spikes! Let's move on to explore the postprocessing capabilities of the `postprocessing` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6. Postprocessing <a class=\"anchor\" id=\"postprocessing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postprocessing spike sorting results ranges from computing additional information, such as spike amplitudes and Principal Component Analisys (PCA) scores, to computing features of the extracellular waveforms, similarity between templates and crosscorrelograms. All of this is possible with the `postprocessing` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparsity\n",
    "\n",
    "Especially when working with silicon high-density probes, or when our probe has multiple groups (e.g. multi-shank, tetrodes), we don't care about waveform/templates on all channels. In order to find a subset of channels for each unit, we can use the `get_template_channel_sparsity()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spost.get_template_channel_sparsity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: radius\n",
    "sparsity_radius = spost.get_template_channel_sparsity(we, method=\"radius\", radius_um=50)\n",
    "print(sparsity_radius[sorting.unit_ids[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: best\n",
    "sparsity_best = spost.get_template_channel_sparsity(we, method=\"best_channels\", num_channels=4)\n",
    "print(sparsity_best[sorting.unit_ids[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the plotting and exporting functions accept `sparsity` as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_unit_templates(we, sparsity=sparsity_radius, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_unit_templates(we, sparsity=sparsity_best, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### PCA scores\n",
    "\n",
    "PCA scores can be easily computed with the `compute_principal_components()` function. Similarly to the `extract_waveforms`, the function returns an object of type `WaveformPrincipalComponent` that allows to retrieve all pc scores on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spost.compute_principal_components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = spost.compute_principal_components(we, n_components=3,\n",
    "                                        sparsity=sparsity_radius, \n",
    "                                        load_if_exists=False,\n",
    "                                        n_jobs=job_kwargs[\"n_jobs\"], \n",
    "                                        progress_bar=job_kwargs[\"progress_bar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pc0 = pc.get_projections(unit_id=0)\n",
    "print(f\"PC scores shape: {pc0.shape}\")\n",
    "all_labels, all_pcs = pc.get_all_projections()\n",
    "print(f\"All PC scores shape: {all_pcs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pc scores of a single unit, the dimension is (num_spikes, num_components, num_channels). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaveformExtensions\n",
    "\n",
    "When we compute PCA (or use other postprocessing functions), the computed information is added to the waveform folder. The functions act as `WaveformExtensions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we.get_available_extension_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `WaveformExtension` is an object that allows us to retrieve the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = we.load_extension(\"principal_components\")\n",
    "print(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels, all_pcs = pc.get_data()\n",
    "print(all_pcs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike amplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spike amplitudes can be computed with the `get_spike_amplitudes` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = spost.compute_spike_amplitudes(we, outputs=\"by_unit\", load_if_exists=True, \n",
    "                                            **job_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By default, all amplitudes are concatenated in one array with all amplitudes form all spikes. With the `output=\"by_unit\"` argument, instead, a dictionary is returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_amplitudes(we, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute unit and spike locations\n",
    "\n",
    "When using silicon probes, we can estimate the unit (or spike) location with triangulation. This can be done either with a simple center of mass or by assuming a monopolar model:\n",
    "\n",
    "$$V_{ext}(\\boldsymbol{r_{ext}}) = \\frac{I_n}{4 \\pi \\sigma |\\boldsymbol{r_{ext}} - \\boldsymbol{r_{n}}|}$$\n",
    "\n",
    "where $\\boldsymbol{r_{n}}$ is the position of the neuron, and $\\boldsymbol{r_{n}}$ of the electrode(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_locations = spost.compute_unit_locations(we, method=\"monopolar_triangulation\", load_if_exists=True)\n",
    "spike_locations = spost.compute_spike_locations(we, method=\"center_of_mass\", load_if_exists=True,\n",
    "                                                **job_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_unit_locations(we, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_spike_locations(we, max_spikes_per_unit=300, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute correlograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccgs, bins = spost.compute_correlograms(we)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_autocorrelograms(we, unit_ids=sorting.unit_ids[:3])\n",
    "sw.plot_crosscorrelograms(we, unit_ids=sorting.unit_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute template similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = spost.compute_template_similarity(we)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute template metrics\n",
    "\n",
    "Template metrics, or extracellular features, such as peak to valley duration or full-width half maximum, are important to classify neurons into putative classes (excitatory - inhibitory). The `postprocessing` allows one to compute several of these metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spost.get_template_metric_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "template_metrics = spost.calculate_template_metrics(we)\n",
    "display(template_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_template_metrics(we, include_metrics=[\"peak_to_valley\", \"half_width\"], \n",
    "                         backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For more information about these template metrics, we refer to this [documentation](https://github.com/AllenInstitute/ecephys_spike_sorting/tree/master/ecephys_spike_sorting/modules/mean_waveforms) from the Allen Institute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 7. Quality metrics and curation <a class=\"anchor\" id=\"curation\"></a>\n",
    "\n",
    "The `qualitymetrics` module also provides several functions to compute qualitity metrics to validate the spike sorting results.\n",
    "\n",
    "Let's see what metrics are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sqm.get_quality_metric_list())\n",
    "print(sqm.get_quality_pca_metric_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qm = sqm.compute_quality_metrics(we, sparsity=sparsity_radius, verbose=True, \n",
    "                                 n_jobs=job_kwargs[\"n_jobs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display(qm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_quality_metrics(we, include_metrics=[\"amplitude_cutoff\", \"presence_ratio\", \"isi_violations_ratio\", \"snr\"], \n",
    "                        backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For more information about these waveform features, we refer to the [SpikeInterface documentation](https://spikeinterface.readthedocs.io/en/latest/module_qualitymetrics.html) and to this excellent [documentation](https://allensdk.readthedocs.io/en/latest/_static/examples/nb/ecephys_quality_metrics.html) from the Allen Institute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Automatic curation based on quality metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A viable option to curate (or at least pre-curate) a spike sorting output is to filter units based on quality metrics. As we have already computed quality metrics a few lines above, we can simply filter the `qm` dataframe based on some thresholds.\n",
    "\n",
    "Here, we'll only keep units with an ISI violation threshold < 0.2 and amplitude cutoff < 0.9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "isi_viol_thresh = 0.2\n",
    "amp_cutoff_thresh = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A straightforward way to filter a pandas dataframe is via the `query`.\n",
    "We first define our query (make sure the names match the column names of the dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "our_query = f\"amplitude_cutoff < {amp_cutoff_thresh} & isi_violations_rate < {isi_viol_thresh}\"\n",
    "print(our_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "and then we can use the query to select units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keep_units = qm.query(our_query)\n",
    "keep_unit_ids = keep_units.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_auto_KS25 = sorting.select_units(keep_unit_ids)\n",
    "print(f\"Number of units before curation: {len(sorting.get_unit_ids())}\")\n",
    "print(f\"Number of units after curation: {len(sorting_auto_KS25.get_unit_ids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save all the waveforms and post-processed data for curated units in a separate folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we.select_units?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_curated = we.select_units(keep_unit_ids, new_folder=\"waveforms_cur\")\n",
    "# we_curated = we.select_units(keep_unit_ids, new_folder=None, use_relative_path=\"waveforms_curated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(we_curated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_curated.get_available_extension_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Viewers <a class=\"anchor\" id=\"viewers\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpikeInterface GUI\n",
    "\n",
    "A QT-based GUI built on top of SpikeInterface objects.\n",
    "\n",
    "Developed by Samuel Garcia, CRNL, Lyon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sigui waveforms/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Summary - SortingView"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sortingview` backend requires an additional step to configure the transfer of the data to be plotted to the cloud. \n",
    "\n",
    "See documentation [here](https://spikeinterface.readthedocs.io/en/latest/module_widgets.html).\n",
    "\n",
    "Developed by Jeremy Magland and Jeff Soules, Flatiron Institute, NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_sorting_summary(we_curated, sparsity=sparsity_radius, backend=\"sortingview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Spike sorting comparison <a class=\"anchor\" id=\"comparison\"></a>\n",
    "\n",
    "Can we combine the output of multiple sorters to curate the spike sorting output?\n",
    "\n",
    "To answer this question we can use the `comparison` module.\n",
    "We first compare and match the output spike trains of the different sorters, and we can then extract a new `SortingExtractor` with only the units in agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare two sorters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_KS2_KS25 = sc.compare_two_sorters(sorting_KS2, sorting_KS25, 'KS2', 'KS25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_agreement_matrix(comp_KS2_KS25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_KS2_KS25auto = sc.compare_two_sorters(sorting_KS2, sorting_auto_KS25, 'KS2', 'KS25_auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_agreement_matrix(comp_KS2_KS25auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare multiple sorters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmp = sc.compare_multiple_sorters([sorting_KS2, sorting_KS25], ['KS2', 'KS25'], \n",
    "                                   spiketrain_mode='union', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sw.plot_multicomp_agreement(mcmp)\n",
    "w = sw.plot_multicomp_agreement_by_sorter(mcmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sw.plot_multicomp_graph(mcmp, draw_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement_sorting = mcmp.get_agreement_sorting(minimum_agreement_count=2)\n",
    "print(agreement_sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_rasters(agreement_sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare consensus and auto\n",
    "comp_agr_auto = sc.compare_two_sorters(agreement_sorting, sorting_auto_KS25, 'AGR', 'AUTO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_agreement_matrix(comp_agr_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 10. Exporters <a class=\"anchor\" id=\"exporters\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Export to Phy for manual curation\n",
    "\n",
    "To perform manual curation we can export the data to [Phy](https://github.com/cortex-lab/phy). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexp.export_to_phy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sexp.export_to_phy(we, output_folder=base_folder / 'phy_KS25', \n",
    "                   compute_amplitudes=False, compute_pc_features=False, copy_binary=True,\n",
    "                   **job_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with the latest version of Phy so we need to set an environment variable to make it work properly:\n",
    "\n",
    "- Python:\n",
    "```\n",
    "import os\n",
    "os.environ[\"QTWEBENGINE_CHROMIUM_FLAGS\"] = \"--single-process\"\n",
    "```\n",
    "\n",
    "- OR terminal:\n",
    "\n",
    "  - Linux/MacOS:\n",
    "`export QTWEBENGINE_CHROMIUM_FLAGS=\"--single-process\"`\n",
    "\n",
    "  - Windows:\n",
    "`set QTWEBENGINE_CHROMIUM_FLAGS=\"--single-process\"`\n",
    "\n",
    "Then we can run the Phy GUI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"QTWEBENGINE_CHROMIUM_FLAGS\"] = \"--single-process\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%capture --no-display\n",
    "# !phy template-gui phy_KS25/params.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After curating the results we can reload it using the `PhySortingExtractor` and exclude the units that we labeled as `noise`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_phy_curated = se.PhySortingExtractor(base_folder / 'phy_KS25/', exclude_cluster_groups=['noise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of units before curation: {len(sorting.get_unit_ids())}\")\n",
    "print(f\"Number of units after curation: {len(sorting_phy_curated.get_unit_ids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's all for today! Thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
